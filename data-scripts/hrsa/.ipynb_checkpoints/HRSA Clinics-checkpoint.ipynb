{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv, requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeHrsa(pageList):\n",
    "    for idx, abr in enumerate(pageList):\n",
    "        page = requests.get(f'https://www.hrsa.gov/coronavirus/health-center-program/participants/{abr}')\n",
    "        html = page.text\n",
    "        soup = BeautifulSoup(html)\n",
    "        table = soup.find('table')\n",
    "\n",
    "        output_rows = []\n",
    "        columnHeaders = ['Health Center Name', 'City', 'State', 'Status']\n",
    "        for table_row in table.findAll('tr'):\n",
    "            columns = table_row.findAll('td')\n",
    "            if len(columns) == 0:\n",
    "                continue\n",
    "            output_row = {}\n",
    "            for i in range(0, 4):\n",
    "                output_row[columnHeaders[i]] = columns[i].text\n",
    "            output_rows.append(output_row)\n",
    "\n",
    "        if idx == 0:\n",
    "            combinedDf = pd.DataFrame(output_rows)\n",
    "        else:\n",
    "            combinedDf = pd.concat([combinedDf, pd.DataFrame(output_rows)])\n",
    "            \n",
    "    geocodedClinics = pd.read_csv('full_clinics_geocoded.csv')\n",
    "    merged = combinedDf.merge(geocodedClinics, on=[\"Health Center Name\", 'City', 'State'], how=\"left\")\n",
    "    \n",
    "    return {\n",
    "        'missingData':merged[merged.address.isnull()],\n",
    "        'clinics':merged[merged.address.notnull()],\n",
    "        'full':combinedDf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFederalSites():\n",
    "    pastData = pd.read_csv('../../public/csv/context_vaccination_sites_hrsa_wh.csv')\n",
    "    return pastData[pastData.type==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-187-f0d775f25bfa>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-187-f0d775f25bfa>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    API_KEY = # GCP PLACES AND MAPS API KEY HERE\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def handleMissingData(placeList):\n",
    "    API_KEY = # GCP PLACES AND MAPS API KEY HERE\n",
    "    \n",
    "    def combineKey(row):\n",
    "        return f'{row[\"Health Center Name\"]}, {row[\"City\"]}, {row[\"State\"]}'\n",
    "    \n",
    "    placeList['lat'] = None\n",
    "    placeList['lon'] = None\n",
    "    placeList['address'] = ''\n",
    "    placeList['phone'] = ''\n",
    "    placeList['combinedKey'] = placeList.apply(lambda x: combineKey(x), axis=1)\n",
    "    \n",
    "    \n",
    "    placeIDs = []\n",
    "    for PLACE in placeList[placeList.lat.isnull()]['combinedKey']:\n",
    "        rtn = requests.get(f'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?key={API_KEY}&input={PLACE}&inputtype=textquery')\n",
    "        placeIDs.append({\n",
    "            'name': PLACE,\n",
    "            'candidates': rtn.json()['candidates']\n",
    "        })\n",
    "        \n",
    "    for i in range(0, len(placeIDs)):\n",
    "        details = []\n",
    "        for Candidate in placeIDs[i]['candidates']:\n",
    "            rtn = requests.get(f'https://maps.googleapis.com/maps/api/place/details/json?key={API_KEY}&place_id={Candidate[\"place_id\"]}')\n",
    "            details.append(rtn.json())\n",
    "        placeIDs[i]['details'] = details\n",
    "    \n",
    "    for place in placeIDs:\n",
    "        if (len(place['details']) == 0):\n",
    "            continue\n",
    "        place['result'] = place['details'][0]\n",
    "        \n",
    "    cleanData = []\n",
    "    \n",
    "    for place in placeIDs:\n",
    "        if (len(place['details']) == 0):\n",
    "            continue\n",
    "\n",
    "        tempObj = {}\n",
    "\n",
    "        try:\n",
    "            tempObj['combinedKey'] = place['name'],\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            tempObj['name'] = place['result']['result']['name']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            tempObj['address'] = place['result']['result']['formatted_address']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            tempObj['contact'] = place['result']['result']['formatted_phone_number']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            tempObj['lat'] = place['result']['result']['geometry']['location']['lat']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            tempObj['lon'] = place['result']['result']['geometry']['location']['lng']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cleanData.append(tempObj)\n",
    "    \n",
    "    cleanLocations = pd.DataFrame(cleanData)\n",
    "    return cleanLocations\n",
    "    cleanLocations['combinedKey'] = cleanLocations.combinedKey.astype(str).str.slice(2,-3)\n",
    "    \n",
    "    return cleanLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateGeocodedList(newData):\n",
    "    # call geocoded csv\n",
    "    geocodedClinics = pd.read_csv('full_clinics_geocoded.csv')\n",
    "    # filter out new entries\n",
    "    geocodedClinics = geocodedClinics[~geocodedClinics['Health Center Name'].isin(newData['Health Center Name'])]\n",
    "    # concat with new data and return\n",
    "    combinedData = pd.concat([geocodedClinics, newData], sort=False)\n",
    "    return combinedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAndExport(clinicData, federalData):\n",
    "    geocodedClinics = pd.read_csv('full_clinics_geocoded.csv')\n",
    "    # merge with geocoded\n",
    "    merged = clinicData.merge(geocodedClinics, on=[\"Health Center Name\", 'City', 'State'], how=\"left\")\n",
    "    # drop missing geometry\n",
    "    merged = merged[merged.lat.notnull()]\n",
    "    \n",
    "    def translateStatus(val):\n",
    "        if val == 'Invited':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    merged['Status'] = merged['Status'].apply(lambda x: translateStatus(x))\n",
    "    cleaned = merged[['name','lon','lat','Status','address','contact']]\n",
    "    cleaned.columns = ['name','lon','lat','type','address','phone']\n",
    "    \n",
    "    return pd.concat([federalData, cleaned], sort=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scrape Current Data\n",
    "pageList = ['AL','AK','AS','AZ','AR','CA','CO','CT','DE','DC','FM','FL','GA','GU','HI','ID','IL','IN','IA','KS','KY','LA','ME','MH','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PW','PA','PR','RI','SC','SD','TN','TX','UT','VT','VI','VA','WA','WV','WI','WY']\n",
    "currentData = scrapeHrsa(pageList)\n",
    "\n",
    "# Get Past Data\n",
    "federalSites = getFederalSites()\n",
    "\n",
    "# Handle Missing Entries\n",
    "try:\n",
    "    newData = handleMissingData(currentData['missingData'])\n",
    "    # newData['combinedKey'] = newData.combinedKey.astype(str).str.slice(2,-3)\n",
    "\n",
    "    joinedNewData = currentData['missingData'][['Health Center Name', 'City', 'State', 'combinedKey']] \\\n",
    "        .merge(newData, how=\"left\", on=\"combinedKey\")\n",
    "\n",
    "    # Combine New Data\n",
    "    newGeocodedData = updateGeocodedList(joinedNewData)\n",
    "    newGeocodedData[['City', 'Health Center Name', 'State', 'address',\n",
    "           'combinedKey', 'contact', 'lat', 'lon', 'name']].to_csv('full_clinics_geocoded.csv',index=False)\n",
    "except:\n",
    "    ## data can't be found :/\n",
    "    pass\n",
    "\n",
    "cleanedData = cleanAndExport(currentData['full'], federalSites)\n",
    "cleanedData.to_csv('../../public/csv/context_vaccination_sites_hrsa_wh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
