{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = requests.get('https://covid.cdc.gov/covid-data-tracker/COVIDData/getAjaxData?id=vaccination_data')\n",
    "loadedJson = raw.json()['vaccination_data']\n",
    "vaccinationData = pd.DataFrame(loadedJson)\n",
    "\n",
    "with open(f'./json/cdc_vaccine_data_{loadedJson[0][\"Date\"]}.json', 'w') as outfile:\n",
    "    json.dump(loadedJson, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-133-e8ab5655eada>:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  merged = pd.concat([placeholderDf, vaccineAdministered])\n",
      "<ipython-input-133-e8ab5655eada>:38: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  merged = pd.concat([placeholderDf, vaccineDistributed])\n"
     ]
    }
   ],
   "source": [
    "dateDf = pd.read_csv('../../docs/csv/covid_confirmed_1p3a_state.csv')\n",
    "datesList = list(dateDf.columns[2:])\n",
    "datesList.sort()\n",
    "datesList = ['GEOID', 'NAME'] + datesList\n",
    "placeholderDf = pd.DataFrame(datesList).set_index(0).T\n",
    "\n",
    "for idx, file in enumerate(vaccinationDataList):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "        if (type(data)==dict):\n",
    "            data = data['vaccination_data']\n",
    "    currDate = data[0]['Date']\n",
    "    vaccinationDf = pd.DataFrame(data) \\\n",
    "        .merge(geoidTable, left_on=\"Location\", right_on=\"STUSPS\", how=\"inner\")[['GEOID','NAME','Doses_Distributed','Doses_Administered']]\n",
    "    \n",
    "    if idx == 0:\n",
    "        vaccineAdministered = vaccinationDf[['GEOID','NAME','Doses_Administered']]\n",
    "        vaccineDistributed = vaccinationDf[['GEOID','NAME','Doses_Distributed']]\n",
    "        vaccineAdministered.columns = ['GEOID','NAME',currDate]\n",
    "        vaccineDistributed.columns = ['GEOID','NAME',currDate]\n",
    "    else:\n",
    "        dailyVaccineAdministered = vaccinationDf[['GEOID','NAME','Doses_Administered']]\n",
    "        dailyVaccineDistributed = vaccinationDf[['GEOID','NAME','Doses_Distributed']]\n",
    "        dailyVaccineAdministered.columns = ['GEOID','NAME',currDate]\n",
    "        dailyVaccineDistributed.columns = ['GEOID','NAME',currDate]\n",
    "        \n",
    "        vaccineAdministered = vaccineAdministered.merge(dailyVaccineAdministered, on=[\"GEOID\",\"NAME\"])\n",
    "        vaccineDistributed = vaccineDistributed.merge(dailyVaccineDistributed, on=[\"GEOID\",\"NAME\"])\n",
    "        \n",
    "merged = pd.concat([placeholderDf, vaccineAdministered])\n",
    "cols = list(merged.columns)[-2:] + list(merged.columns)[:-2]\n",
    "merged = merged[cols]\n",
    "merged.to_csv()\n",
    "\n",
    "merged.to_csv('./csv/vaccine_admin_cdc_1p3a_state.csv', index=False)\n",
    "merged.to_csv('../../docs/csv/vaccine_admin_cdc_1p3a_state.csv', index=False)\n",
    "\n",
    "merged = pd.concat([placeholderDf, vaccineDistributed])\n",
    "cols = list(merged.columns)[-2:] + list(merged.columns)[:-2]\n",
    "merged = merged[cols]\n",
    "merged.to_csv()\n",
    "\n",
    "merged.to_csv('./csv/vaccine_dist_cdc_1p3a_state.csv', index=False)\n",
    "merged.to_csv('../../docs/csv/vaccine_dist_cdc_1p3a_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-134-6c298b75b39d>:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  merged = pd.concat([placeholderDf, vaccineAdministered])\n",
      "<ipython-input-134-6c298b75b39d>:38: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  merged = pd.concat([placeholderDf, vaccineDistributed])\n"
     ]
    }
   ],
   "source": [
    "dateDf = pd.read_csv('../../docs/csv/covid_confirmed_nyt_state.csv')\n",
    "datesList = list(dateDf.columns[1:])\n",
    "datesList.sort()\n",
    "datesList = ['fips'] + datesList\n",
    "placeholderDf = pd.DataFrame(datesList).set_index(0).T\n",
    "\n",
    "for idx, file in enumerate(vaccinationDataList):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "        if (type(data)==dict):\n",
    "            data = data['vaccination_data']\n",
    "    currDate = data[0]['Date']\n",
    "    vaccinationDf = pd.DataFrame(data) \\\n",
    "        .merge(geoidTable, left_on=\"Location\", right_on=\"STUSPS\", how=\"inner\")[['GEOID','NAME','Doses_Distributed','Doses_Administered']]\n",
    "    \n",
    "    if idx == 0:\n",
    "        vaccineAdministered = vaccinationDf[['GEOID','Doses_Administered']]\n",
    "        vaccineDistributed = vaccinationDf[['GEOID','Doses_Distributed']]\n",
    "        vaccineAdministered.columns = ['fips',currDate]\n",
    "        vaccineDistributed.columns = ['fips',currDate]\n",
    "    else:\n",
    "        dailyVaccineAdministered = vaccinationDf[['GEOID','Doses_Administered']]\n",
    "        dailyVaccineDistributed = vaccinationDf[['GEOID','Doses_Distributed']]\n",
    "        dailyVaccineAdministered.columns = ['fips',currDate]\n",
    "        dailyVaccineDistributed.columns = ['fips',currDate]\n",
    "        \n",
    "        vaccineAdministered = vaccineAdministered.merge(dailyVaccineAdministered, on=[\"fips\"])\n",
    "        vaccineDistributed = vaccineDistributed.merge(dailyVaccineDistributed, on=[\"fips\"])\n",
    "        \n",
    "merged = pd.concat([placeholderDf, vaccineAdministered])\n",
    "cols = list(merged.columns)[-1:] + list(merged.columns)[:-1]\n",
    "merged = merged[cols]\n",
    "merged.to_csv()\n",
    "\n",
    "merged.to_csv('./csv/vaccine_admin_cdc_nyt_state.csv', index=False)\n",
    "merged.to_csv('../../docs/csv/vaccine_admin_cdc_nyt_state.csv', index=False)\n",
    "\n",
    "merged = pd.concat([placeholderDf, vaccineDistributed])\n",
    "cols = list(merged.columns)[-1:] + list(merged.columns)[:-1]\n",
    "merged = merged[cols]\n",
    "merged.to_csv()\n",
    "\n",
    "merged.to_csv('./csv/vaccine_dist_cdc_nyt_state.csv', index=False)\n",
    "merged.to_csv('../../docs/csv/vaccine_dist_cdc_nyt_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cello\\Anaconda3\\lib\\site-packages\\grequests.py:22: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['requests.packages.urllib3.util (C:\\\\Users\\\\cello\\\\Anaconda3\\\\lib\\\\site-packages\\\\requests\\\\packages\\\\urllib3\\\\util\\\\__init__.py)', 'urllib3.contrib.pyopenssl (C:\\\\Users\\\\cello\\\\Anaconda3\\\\lib\\\\site-packages\\\\urllib3\\\\contrib\\\\pyopenssl.py)', 'requests.packages.urllib3.util.ssl_ (C:\\\\Users\\\\cello\\\\Anaconda3\\\\lib\\\\site-packages\\\\requests\\\\packages\\\\urllib3\\\\util\\\\ssl_.py)']. \n",
      "  curious_george.patch_all(thread=False, select=False)\n",
      "C:\\Users\\cello\\Anaconda3\\lib\\site-packages\\gevent\\hub.py:161: UserWarning: libuv only supports millisecond timer resolution; all times less will be set to 1 ms\n",
      "  with loop.timer(seconds, ref=ref) as t:\n"
     ]
    }
   ],
   "source": [
    "import grequests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state2Digit = ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f\"https://covid.cdc.gov/covid-data-tracker/COVIDData/getAjaxData?id=integrated_county_timeseries_state_{stateCode}_external\" for stateCode in state2Digit]\n",
    "breakpoint = 12\n",
    "urlDict = []\n",
    "for i in range(0,5):\n",
    "    urlDict.append(urls[breakpoint*i:breakpoint*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for urlList in urlDict:\n",
    "    rs = (grequests.get(u,  timeout=120) for u in urlList)\n",
    "    response = grequests.map(rs)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = ''\n",
    "\n",
    "for responseSet in responses:\n",
    "    for response in responseSet:\n",
    "        if len(parsed)==0:\n",
    "            parsed = pd.DataFrame(response.json()['integrated_county_timeseries_external_data'])\n",
    "        else:\n",
    "            parsed = pd.concat([parsed, pd.DataFrame(response.json()['integrated_county_timeseries_external_data'])])\n",
    "\n",
    "parsed = parsed.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips_code', 'state', 'county', 'new_cases_7_day_rolling_average',\n",
       "       'percent_new_test_results_reported_positive_7_day_rolling_average',\n",
       "       'new_cases_week_over_week_percent_change',\n",
       "       'new_test_results_reported_7_day_rolling_average',\n",
       "       'new_deaths_7_day_rolling_average', 'date', 'report_date_window_start',\n",
       "       'report_date_window'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnList = ['new_cases_7_day_rolling_average', 'new_test_results_reported_7_day_rolling_average','new_deaths_7_day_rolling_average','percent_new_test_results_reported_positive_7_day_rolling_average']\n",
    "csvNames = ['covid_confirmed', 'testing', 'covid_deaths', 'wk_tpos']\n",
    "uniqFips = list(parsed.fips_code.unique())\n",
    "\n",
    "for idx, column in enumerate(columnList):\n",
    "    cleaned = ''\n",
    "\n",
    "    for fips in uniqFips:\n",
    "        if len(cleaned) == 0:\n",
    "            cleaned = parsed[parsed.fips_code == fips][['date','percent_new_test_results_reported_positive_7_day_rolling_average']] \\\n",
    "                .set_index('date').T\n",
    "            cleaned['fips'] = fips\n",
    "        else:\n",
    "            tempDf = parsed[parsed.fips_code == fips][['date','percent_new_test_results_reported_positive_7_day_rolling_average']] \\\n",
    "                .set_index('date').T\n",
    "            tempDf['fips'] = fips\n",
    "            cleaned = pd.concat([cleaned, tempDf])\n",
    "    cleaned = cleaned[list(cleaned.columns)[-1:] + list(cleaned.columns)[:-1]]\n",
    "    columnNames = [col[:10] for col in cleaned.columns]\n",
    "    cleaned.columns = columnNames\n",
    "    cleaned.to_csv(f\"./csv/{csvNames[idx]}_cdc.csv\",index=False)\n",
    "    cleaned.to_csv(f\"../../docs/csv/{csvNames[idx]}_cdc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.to_csv(\"./county_testing_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
