{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from glob import glob\n",
    "import json, requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadCDCdata():\n",
    "    # front end CDC page with links\n",
    "    URL = 'https://beta.healthdata.gov/National/COVID-19-Community-Profile-Report/gqxm-d9w9'\n",
    "\n",
    "    # download Page as HTML\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    # parse HTML with BS4\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # find the script block with the URLs we need\n",
    "    for a in soup.find_all('script'):\n",
    "        if 'initialState' in str(a):\n",
    "            linkBlock = str(a)[69:-17].split('},{')\n",
    "\n",
    "    # declare list to be populated\n",
    "    cleanedLinks = []\n",
    "\n",
    "    # pull out clean links to list\n",
    "    # the reason for this is that the links are not just dates --\n",
    "    # each has a UUID we need to scrape in order to download the excel\n",
    "    for link in linkBlock:\n",
    "        cleaned = link.split('\"href\":\"')[-1].split(',\"link\"')[0]\n",
    "        if ('Community_Profile_Report' in cleaned) and ('/api/views/' in cleaned) and ('Public.xlsx' in cleaned) and (len(cleaned) < 300):\n",
    "            cleanedLinks.append(f\"https://beta.healthdata.gov{cleaned}\")\n",
    "\n",
    "    # check out current excel files\n",
    "    downloadFiles = glob('./xlsx/*.xlsx')\n",
    "\n",
    "    # download any files we're missing in the xlsx folder\n",
    "    for url in cleanedLinks:\n",
    "        r = requests.get(url)\n",
    "        date = url[-21:-13]\n",
    "        if f\"./xlsx\\\\CDC_{url[-21:-13]}.xlsx\" not in downloadFiles:\n",
    "            with open(f\"./xlsx/CDC_{date}.xlsx\", 'wb') as f:\n",
    "                f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findColumn(columns, search):\n",
    "    for column in columns:\n",
    "        if search.lower() in column.lower():\n",
    "            return column\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCDCdata(fileList):\n",
    "    for index, file in enumerate(fileList):\n",
    "        # import excel sheets\n",
    "        raw = pd.read_excel(file, sheet_name=\"Counties\")\n",
    "        # snag case and testing dates\n",
    "        endOfWeekCases = f\"{raw.columns[14].split('(')[-1].split(' ')[0]} {raw.columns[14].split('-')[-1][:-1]}\"\n",
    "        endofWeekCases = datetime.strptime(endOfWeekCases, '%B %d')\n",
    "        endOfWeekTesting = f\"{raw.columns[32].split('(')[-1].split(' ')[0]} {raw.columns[32].split('-')[-1][:-1]}\"\n",
    "        endOfWeekTesting = datetime.strptime(endOfWeekTesting, '%B %d')\n",
    "        year = file[-13:-9]\n",
    "        # set second row as column index\n",
    "        # this is to handle the CDC excel formatting\n",
    "        raw.columns = list(raw.iloc[0])\n",
    "        raw = raw.drop(index=0)\n",
    "        columns = list(raw.columns)\n",
    "\n",
    "\n",
    "        cases = raw[['FIPS code', findColumn(list(raw.columns), 'cumulative cases')]]\n",
    "        cases.columns = ['FIPS', f\"{endofWeekCases.month}/{endofWeekCases.day}/{year}\"]   \n",
    "        \n",
    "        deaths = raw[['FIPS code',findColumn(list(raw.columns), 'cumulative deaths')]]\n",
    "        cases.columns = ['FIPS', f\"{endofWeekCases.month}/{endofWeekCases.day}/{year}\"]\n",
    "\n",
    "        testingPos = raw[['FIPS code',  findColumn(list(raw.columns), 'test positivity rate - last 7 day')]]\n",
    "        testingPos.columns = ['FIPS', f\"{endOfWeekTesting.month}/{endOfWeekTesting.day}/{year}\"]\n",
    "\n",
    "        testing = raw[['FIPS code', findColumn(list(raw.columns), 'Total RT-PCR diagnostic tests - last 7 days')]]\n",
    "        testing.columns = ['FIPS', f\"{endOfWeekTesting.month}/{endOfWeekTesting.day}/{year}\"]\n",
    "\n",
    "        testingCap = raw[['FIPS code', findColumn(list(raw.columns), 'RT-PCR tests per 100k - previous 7 days')]]\n",
    "        testingCap.columns = ['FIPS', f\"{endOfWeekTesting.month}/{endOfWeekTesting.day}/{year}\"]\n",
    "\n",
    "        testingCcpt = raw[['FIPS code',  findColumn(list(raw.columns), 'cases - last 7 days'),  findColumn(list(raw.columns), 'Total RT-PCR diagnostic tests - last 7 days')]]\n",
    "        testingCcpt.columns = ['FIPS', 'Cases', 'Tests']\n",
    "\n",
    "        testingCcptFiltered = testingCcpt.query('Tests > 0')\n",
    "        testingCcptFiltered['CCPT'] = testingCcptFiltered['Cases']/testingCcptFiltered['Tests']\n",
    "\n",
    "        testingCcpt = testingCcpt.merge(testingCcptFiltered, on=['FIPS','Cases','Tests'], how=\"left\")[['FIPS','CCPT']]\n",
    "        testingCcpt.columns = ['FIPS', f\"{endOfWeekTesting.month}/{endOfWeekTesting.day}/{year}\"]\n",
    "\n",
    "        prevCases = cases.copy()\n",
    "        prevDeaths = deaths.copy()\n",
    "        prevTesting = testing.copy()\n",
    "        prevTestingPos = testingPos.copy()\n",
    "        prevTestingCap = testingCap.copy()\n",
    "        prevTestingCcpt = testingCcpt.copy()\n",
    "\n",
    "        if index != 0:\n",
    "            if list(cases.columns)[1] not in list(prevCases.columns):\n",
    "                prevCases = prevCases.merge(cases, on=\"FIPS\", how=\"outer\")\n",
    "            if list(deaths.columns)[1] not in list(prevDeaths.columns):\n",
    "                prevDeaths = prevDeaths.merge(deaths, on=\"FIPS\", how=\"outer\")\n",
    "            if list(testing.columns)[1] not in list(prevTesting.columns):\n",
    "                prevTesting = prevTesting.merge(testing, on=\"FIPS\", how=\"outer\")\n",
    "            if list(testingPos.columns)[1] not in list(prevTestingPos.columns):\n",
    "                prevTestingPos = prevTestingPos.merge(testingPos, on=\"FIPS\", how=\"outer\")\n",
    "            if list(testingCap.columns)[1] not in list(prevTestingCap.columns):\n",
    "                prevTestingCap = prevTestingCap.merge(testingCap, on=\"FIPS\", how=\"outer\")\n",
    "            if list(testingCcpt.columns)[1] not in list(prevTestingCcpt.columns):\n",
    "                prevTestingCcpt = prevTestingCcpt.merge(testingCcpt, on=\"FIPS\", how=\"outer\")\n",
    "    \n",
    "    prevCases.to_csv('./csv/covid_confirmed_cdc.csv',index=False)\n",
    "    prevDeaths.to_csv('./csv/covid_deaths_cdc.csv',index=False)\n",
    "    prevTesting.to_csv('./csv/covid_testing_cdc.csv',index=False)\n",
    "    prevTestingPos.to_csv('./csv/covid_wk_pos_cdc.csv',index=False)\n",
    "    prevTestingCap.to_csv('./csv/covid_tcap_cdc.csv',index=False)\n",
    "    prevTestingCcpt.to_csv('./csv/covid_ccpt_cdc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./xlsx\\CDC_20201217.xlsx\n",
      "1900-12-16 00:00:00\n",
      "1900-12-14 00:00:00\n",
      "./xlsx\\CDC_20201218.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-179-446044abee93>:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testingCcptFiltered['CCPT'] = testingCcptFiltered['Cases']/testingCcptFiltered['Tests']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900-12-17 00:00:00\n",
      "1900-12-15 00:00:00\n",
      "./xlsx\\CDC_20201219.xlsx\n",
      "1900-12-18 00:00:00\n",
      "1900-12-16 00:00:00\n",
      "./xlsx\\CDC_20201220.xlsx\n",
      "1900-12-19 00:00:00\n",
      "1900-12-17 00:00:00\n",
      "./xlsx\\CDC_20201221.xlsx\n",
      "1900-12-20 00:00:00\n",
      "1900-12-18 00:00:00\n",
      "./xlsx\\CDC_20201222.xlsx\n",
      "1900-12-21 00:00:00\n",
      "1900-12-19 00:00:00\n",
      "./xlsx\\CDC_20201223.xlsx\n",
      "1900-12-22 00:00:00\n",
      "1900-12-20 00:00:00\n",
      "./xlsx\\CDC_20201226.xlsx\n",
      "1900-12-25 00:00:00\n",
      "1900-12-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "downloadCDCdata()\n",
    "parseCDCdata(glob('./xlsx/*.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
